import streamlit as st
import requests
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import math
from datetime import datetime, timedelta
import time
import pytz

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Cloudflare AI Gateway Dashboard",
    page_icon="üîÆ",
    layout="wide"
)

def fetch_all_logs(base_url, headers):
    """Busca todos os logs de todas as p√°ginas"""
    all_logs = []
    page = 1
    
    # Progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Primeira requisi√ß√£o para descobrir o total de p√°ginas
        url = f"{base_url}?page={page}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        data = response.json()
        
        if not data.get('success', False):
            st.error(f"Erro na API: {data}")
            return []
        
        result_info = data.get('result_info', {})
        total_count = result_info.get('total_count', 0)
        per_page = result_info.get('per_page', 20)
        total_pages = math.ceil(total_count / per_page)
        
        st.info(f"Total de registros: {total_count} | Total de p√°ginas: {total_pages}")
        
        # Adiciona os logs da primeira p√°gina
        all_logs.extend(data.get('result', []))
        
        # Busca as p√°ginas restantes
        for page in range(2, total_pages + 1):
            status_text.text(f"Buscando p√°gina {page} de {total_pages}...")
            progress_bar.progress(page / total_pages)
            
            url = f"{base_url}?page={page}"
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            
            page_data = response.json()
            if page_data.get('success', False):
                all_logs.extend(page_data.get('result', []))
            
            # Pequena pausa para n√£o sobrecarregar a API
            time.sleep(0.1)
        
        progress_bar.progress(1.0)
        status_text.text(f"‚úÖ Carregamento conclu√≠do! {len(all_logs)} registros obtidos.")
        
    except requests.exceptions.RequestException as e:
        st.error(f"Erro na requisi√ß√£o: {e}")
        return []
    except Exception as e:
        st.error(f"Erro inesperado: {e}")
        return []
    
    return all_logs

def process_logs_data(logs):
    """Processa os logs e retorna um DataFrame"""
    processed_data = []
    
    for log in logs:
        email = log.get('metadata', {}).get('email', 'N√£o informado')
        model = log.get('model', 'N√£o informado')
        cost = log.get('cost', 0)
        tokens_in = log.get('tokens_in', 0)
        tokens_out = log.get('tokens_out', 0)
        duration = log.get('duration', 0)
        success = log.get('success', False)
        created_at = log.get('created_at', '')
        provider = log.get('provider', 'N√£o informado')
        
        # Converte created_at para datetime
        try:
            if created_at:
                # Remove o 'Z' e converte para datetime UTC
                created_at_dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            else:
                created_at_dt = None
        except:
            created_at_dt = None
        
        processed_data.append({
            'email': email,
            'model': model,
            'cost': cost,
            'tokens_in': tokens_in,
            'tokens_out': tokens_out,
            'total_tokens': tokens_in + tokens_out,
            'duration': duration,
            'success': success,
            'created_at': created_at,
            'created_at_dt': created_at_dt,
            'provider': provider
        })
    
    df = pd.DataFrame(processed_data)
    
    # Remove registros sem data v√°lida
    df = df.dropna(subset=['created_at_dt'])
    
    return df

def filter_by_date_range(df, date_filter):
    """Filtra o DataFrame por per√≠odo de tempo"""
    if df.empty or 'created_at_dt' not in df.columns:
        return df
    
    # Obt√©m a data/hora atual em UTC
    now_utc = datetime.now(pytz.UTC)
    
    # Define o per√≠odo baseado no filtro
    if date_filter == "√öltimas 24 horas":
        start_date = now_utc - timedelta(hours=24)
    elif date_filter == "√öltimos 3 dias":
        start_date = now_utc - timedelta(days=3)
    elif date_filter == "√öltimos 7 dias":
        start_date = now_utc - timedelta(days=7)
    elif date_filter == "√öltimos 14 dias":
        start_date = now_utc - timedelta(days=14)
    elif date_filter == "√öltimos 30 dias":
        start_date = now_utc - timedelta(days=30)
    else:  # "Todos os dados"
        return df
    
    # Filtra os dados
    filtered_df = df[df['created_at_dt'] >= start_date].copy()
    
    return filtered_df

def create_user_summary(df):
    """Cria resumo por usu√°rio"""
    user_summary = df.groupby('email').agg({
        'cost': 'sum',
        'total_tokens': 'sum',
        'tokens_in': 'sum',
        'tokens_out': 'sum',
        'duration': 'mean',
        'model': 'count',  # Conta total de requests
        'success': lambda x: (x == True).sum()  # Conta requests bem-sucedidos
    }).round(6)
    
    user_summary.columns = ['Custo Total', 'Total Tokens', 'Tokens Input', 'Tokens Output', 'Dura√ß√£o M√©dia (ms)', 'Total Requests', 'Requests Sucesso']
    user_summary['Taxa Sucesso (%)'] = (user_summary['Requests Sucesso'] / user_summary['Total Requests'] * 100).round(2)
    
    return user_summary.sort_values('Custo Total', ascending=False)

def create_model_usage_by_user(df):
    """Cria resumo de uso de modelos por usu√°rio"""
    model_usage = df.groupby(['email', 'model']).agg({
        'cost': 'sum',
        'model': 'count',  # Conta requests
        'total_tokens': 'sum'
    }).round(6)
    
    model_usage.columns = ['Custo', 'Requests', 'Total Tokens']
    
    return model_usage.sort_values(['email', 'Custo'], ascending=[True, False])
    """Cria resumo por usu√°rio"""
    user_summary = df.groupby('email').agg({
        'cost': 'sum',
        'total_tokens': 'sum',
        'tokens_in': 'sum',
        'tokens_out': 'sum',
        'duration': 'mean',
        'model': 'count',  # Conta total de requests
        'success': lambda x: (x == True).sum()  # Conta requests bem-sucedidos
    }).round(6)
    
    user_summary.columns = ['Custo Total', 'Total Tokens', 'Tokens Input', 'Tokens Output', 'Dura√ß√£o M√©dia (ms)', 'Total Requests', 'Requests Sucesso']
    user_summary['Taxa Sucesso (%)'] = (user_summary['Requests Sucesso'] / user_summary['Total Requests'] * 100).round(2)
    
    return user_summary.sort_values('Custo Total', ascending=False)

def create_model_usage_by_user(df):
    """Cria resumo de uso de modelos por usu√°rio"""
    model_usage = df.groupby(['email', 'model']).agg({
        'cost': 'sum',
        'model': 'count',  # Conta requests
        'total_tokens': 'sum'
    }).round(6)
    
    model_usage.columns = ['Custo', 'Requests', 'Total Tokens']
    
    return model_usage.sort_values(['email', 'Custo'], ascending=[True, False])

# Interface principal
st.title("üîÆ Cloudflare AI Gateway Dashboard")
st.markdown("---")

# Configura√ß√µes na sidebar
st.sidebar.title("‚öôÔ∏è Configura√ß√µes")

# Input para URL base (sem par√¢metros)
default_url = ""
base_url = st.sidebar.text_input(
    "URL da API (sem par√¢metros):",
    value=default_url,
    help="Insira a URL base da API do Cloudflare AI Gateway"
)

# Input para token de autoriza√ß√£o
auth_token = st.sidebar.text_input(
    "Token de Autoriza√ß√£o:",
    type="password",
    help="Token Bearer para autentica√ß√£o"
)

# Input para email (opcional)
auth_email = st.sidebar.text_input(
    "Email da conta Cloudflare (opcional):",
    help="Email associado √† conta Cloudflare"
)

if st.sidebar.button("üîÑ Carregar Dados", type="primary"):
    if not base_url or not auth_token:
        st.error("Por favor, preencha a URL da API e o token de autoriza√ß√£o.")
    else:
        # Prepara headers
        headers = {
            "Authorization": f"Bearer {auth_token}",
            "Content-Type": "application/json"
        }
        
        if auth_email:
            headers["X-Auth-Email"] = auth_email
        
        with st.spinner("Carregando dados da API..."):
            logs = fetch_all_logs(base_url, headers)
        
        if logs:
            # Processa os dados
            df = process_logs_data(logs)
            
            # Salva no session state
            st.session_state['df'] = df
            st.session_state['last_update'] = datetime.now()
            
            st.success(f"‚úÖ Dados carregados com sucesso! {len(logs)} registros processados.")

# Verifica se h√° dados carregados
if 'df' in st.session_state:
    df_original = st.session_state['df']
    last_update = st.session_state.get('last_update', 'Desconhecido')
    
    # Filtros de data
    st.markdown("## üóìÔ∏è Filtros")
    
    col_filter1, col_filter2 = st.columns([2, 1])
    
    with col_filter1:
        # Filtro de per√≠odo
        date_options = [
            "Todos os dados",
            "√öltimas 24 horas", 
            "√öltimos 3 dias",
            "√öltimos 7 dias", 
            "√öltimos 30 dias"
        ]
        
        selected_period = st.selectbox(
            "üìÖ Per√≠odo:",
            options=date_options,
            index=0,
            help="Filtre os dados por per√≠odo de tempo"
        )
    
    with col_filter2:
        # Mostra informa√ß√µes do per√≠odo de dados
        if not df_original.empty and 'created_at_dt' in df_original.columns:
            min_date = df_original['created_at_dt'].min()
            max_date = df_original['created_at_dt'].max()
            st.info(f"üìä Dados de {min_date.strftime('%d/%m/%Y %H:%M')} at√© {max_date.strftime('%d/%m/%Y %H:%M')}")
    
    # Aplica o filtro de data
    df = filter_by_date_range(df_original, selected_period)
    
    # Mostra informa√ß√µes sobre o filtro aplicado
    if selected_period != "Todos os dados":
        filtered_count = len(df)
        total_count = len(df_original)
        st.success(f"üéØ Filtro aplicado: **{selected_period}** | Mostrando {filtered_count:,} de {total_count:,} registros")
    else:
        st.info(f"üìä Dados carregados: {len(df):,} registros | √öltima atualiza√ß√£o: {last_update}")
    
    # Verifica se ainda h√° dados ap√≥s o filtro
    if df.empty:
        st.warning("‚ö†Ô∏è Nenhum dado encontrado para o per√≠odo selecionado.")
        st.stop()
    
    st.markdown("---")
    
    # M√©tricas gerais
    st.markdown("## üìà M√©tricas Gerais")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Total de Usu√°rios",
            df['email'].nunique(),
            help="N√∫mero √∫nico de usu√°rios"
        )
    
    with col2:
        st.metric(
            "Custo Total",
            f"${df['cost'].sum():.6f}",
            help="Soma de todos os custos"
        )
    
    with col3:
        st.metric(
            "Total de Requests",
            f"{len(df):,}",
            help="N√∫mero total de requisi√ß√µes"
        )
    
    with col4:
        success_rate = (df['success'].sum() / len(df) * 100)
        st.metric(
            "Taxa de Sucesso",
            f"{success_rate:.1f}%",
            help="Porcentagem de requisi√ß√µes bem-sucedidas"
        )
    
    # Resumo por usu√°rio
    st.markdown("## üë• Resumo por Usu√°rio")
    
    user_summary = create_user_summary(df)
    st.dataframe(user_summary, use_container_width=True)
    
    # Gr√°ficos
    st.markdown("## üìä Visualiza√ß√µes")
    
    # Abas para diferentes visualiza√ß√µes
    tab1, tab2, tab3, tab4 = st.tabs(["üí∞ Custos por Usu√°rio", "ü§ñ Modelos Mais Usados", "üìà Uso de Tokens", "‚è±Ô∏è Performance"])
    
    with tab1:
        # Gr√°fico de custos por usu√°rio
        fig_cost = px.bar(
            user_summary.head(10).reset_index(),
            x='email',
            y='Custo Total',
            title="Top 10 Usu√°rios por Custo Total",
            labels={'email': 'Usu√°rio', 'Custo Total': 'Custo ($)'}
        )
        fig_cost.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig_cost, use_container_width=True)
    
    with tab2:
        # Gr√°fico de modelos mais usados
        model_usage = df.groupby('model').agg({
            'cost': 'sum',
            'model': 'count'
        }).round(6)
        model_usage.columns = ['Custo Total', 'Total Requests']
        model_usage = model_usage.sort_values('Total Requests', ascending=False)
        
        fig_models = px.pie(
            model_usage.head(10).reset_index(),
            values='Total Requests',
            names='model',
            title="Distribui√ß√£o de Uso por Modelo (Top 10)"
        )
        st.plotly_chart(fig_models, use_container_width=True)
        
        # Tabela de modelos
        st.subheader("Detalhes por Modelo")
        st.dataframe(model_usage, use_container_width=True)
    
    with tab3:
        # Gr√°fico de tokens por usu√°rio
        fig_tokens = px.bar(
            user_summary.head(10).reset_index(),
            x='email',
            y='Total Tokens',
            title="Top 10 Usu√°rios por Total de Tokens",
            labels={'email': 'Usu√°rio', 'Total Tokens': 'Tokens'}
        )
        fig_tokens.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig_tokens, use_container_width=True)
    
    with tab4:
        # Gr√°fico de dura√ß√£o m√©dia por usu√°rio
        fig_duration = px.bar(
            user_summary.head(10).reset_index(),
            x='email',
            y='Dura√ß√£o M√©dia (ms)',
            title="Top 10 Usu√°rios por Dura√ß√£o M√©dia de Request",
            labels={'email': 'Usu√°rio', 'Dura√ß√£o M√©dia (ms)': 'Dura√ß√£o (ms)'}
        )
        fig_duration.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig_duration, use_container_width=True)
    
    # Detalhes por usu√°rio e modelo
    st.markdown("## üîç Detalhes por Usu√°rio e Modelo")
    
    model_usage_detailed = create_model_usage_by_user(df)
    
    # Filtro por usu√°rio
    selected_user = st.selectbox(
        "Selecione um usu√°rio para ver detalhes:",
        options=['Todos'] + list(df['email'].unique()),
        index=0
    )
    
    if selected_user != 'Todos':
        filtered_data = model_usage_detailed.loc[selected_user]
        st.subheader(f"Uso de Modelos - {selected_user}")
        st.dataframe(filtered_data, use_container_width=True)
        
        # Gr√°fico para o usu√°rio selecionado
        fig_user_models = px.pie(
            filtered_data.reset_index(),
            values='Requests',
            names='model',
            title=f"Distribui√ß√£o de Modelos - {selected_user}"
        )
        st.plotly_chart(fig_user_models, use_container_width=True)
    else:
        st.dataframe(model_usage_detailed, use_container_width=True)

else:
    st.info("üëÜ Configure as credenciais na barra lateral e clique em 'Carregar Dados' para come√ßar.")
    
    # Instru√ß√µes
    st.markdown("""
    ## üìã Como usar:
    
    1. **Configure a URL da API**: Insira a URL base da API do Cloudflare AI Gateway (sem par√¢metros de p√°gina)
    2. **Adicione o Token**: Insira seu token de autoriza√ß√£o Bearer
    3. **Email (opcional)**: Adicione o email associado √† sua conta Cloudflare se necess√°rio
    4. **Carregue os Dados**: Clique no bot√£o "Carregar Dados"
    
    O dashboard ir√°:
    - ‚úÖ Buscar automaticamente todas as p√°ginas de dados
    - üìä Apresentar m√©tricas gerais
    - üë• Mostrar resumo por usu√°rio
    - ü§ñ Exibir modelos mais utilizados
    - üí∞ Calcular custos por usu√°rio e modelo
    - üìà Gerar visualiza√ß√µes interativas
    """)

# Footer
st.markdown("---")
st.markdown("Dashboard criado com ‚ù§Ô∏è usando Streamlit")